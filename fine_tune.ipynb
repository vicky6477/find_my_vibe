{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8465daf9-ad8e-42cd-906f-70f869ccc35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b012a1-fe1b-439a-8b13-efe596a1d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (0.21.0+cu124)\n",
      "Collecting fashion-clip\n",
      "  Downloading fashion_clip-0.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (2.6.0+cu124)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Collecting boto3>=1.10.50 (from fashion-clip)\n",
      "  Downloading boto3-1.38.35-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting appdirs>=1.4.4 (from fashion-clip)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pandas>=1.3.5 in ./.venv/lib/python3.12/site-packages (from fashion-clip) (2.3.0)\n",
      "Collecting pyarrow>=7.0.0 (from fashion-clip)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: matplotlib>=3.5.1 in ./.venv/lib/python3.12/site-packages (from fashion-clip) (3.10.3)\n",
      "Collecting python-dotenv>=0.19.2 (from fashion-clip)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting annoy>=1.17.0 (from fashion-clip)\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers>=4.26.1 (from fashion-clip)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting ipyplot>=1.1.1 (from fashion-clip)\n",
      "  Downloading ipyplot-1.1.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting datasets>=2.10.0 (from fashion-clip)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting validators (from fashion-clip)\n",
      "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting botocore<1.39.0,>=1.38.35 (from boto3>=1.10.50->fashion-clip)\n",
      "  Downloading botocore-1.38.35-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.10.50->fashion-clip)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.10.50->fashion-clip)\n",
      "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.12/site-packages (from botocore<1.39.0,>=1.38.35->boto3>=1.10.50->fashion-clip) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./.venv/lib/python3.12/site-packages (from botocore<1.39.0,>=1.38.35->boto3>=1.10.50->fashion-clip) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.35->boto3>=1.10.50->fashion-clip) (1.17.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.10.0->fashion-clip)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets>=2.10.0->fashion-clip) (2.32.3)\n",
      "Collecting tqdm>=4.66.3 (from datasets>=2.10.0->fashion-clip)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets>=2.10.0->fashion-clip)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.10.0->fashion-clip)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets>=2.10.0->fashion-clip)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets>=2.10.0->fashion-clip) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets>=2.10.0->fashion-clip) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading aiohttp-3.12.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.10.0->fashion-clip) (3.10)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets>=2.10.0->fashion-clip)\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: IPython in ./.venv/lib/python3.12/site-packages (from ipyplot>=1.1.1->fashion-clip) (9.3.0)\n",
      "Collecting shortuuid (from ipyplot>=1.1.1->fashion-clip)\n",
      "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.1->fashion-clip) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.1->fashion-clip) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.1->fashion-clip) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.1->fashion-clip) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.1->fashion-clip) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.5->fashion-clip) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.5->fashion-clip) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.10.0->fashion-clip) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.10.0->fashion-clip) (2025.4.26)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.26.1->fashion-clip)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.26.1->fashion-clip)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.26.1->fashion-clip)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.12/site-packages (from IPython->ipyplot>=1.1.1->fashion-clip) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->ipyplot>=1.1.1->fashion-clip) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->IPython->ipyplot>=1.1.1->fashion-clip) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->IPython->ipyplot>=1.1.1->fashion-clip) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->IPython->ipyplot>=1.1.1->fashion-clip) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->IPython->ipyplot>=1.1.1->fashion-clip) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->IPython->ipyplot>=1.1.1->fashion-clip) (0.2.3)\n",
      "Downloading fashion_clip-0.2.2-py3-none-any.whl (15 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading boto3-1.38.35-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.38.35-py3-none-any.whl (13.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipyplot-1.1.2-py3-none-any.whl (13 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
      "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Building wheels for collected packages: annoy\n",
      "\u001b[33m  DEPRECATION: Building 'annoy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'annoy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for annoy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-linux_x86_64.whl size=551631 sha256=8a2d35076735033a22f8e18945d26b3f15ca5cc547e8570d24b001efaaabe592\n",
      "  Stored in directory: /home/yoda/.cache/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\n",
      "Successfully built annoy\n",
      "Installing collected packages: appdirs, annoy, xxhash, validators, tqdm, shortuuid, safetensors, regex, python-dotenv, pyarrow, propcache, multidict, jmespath, hf-xet, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, botocore, aiosignal, tokenizers, s3transfer, ipyplot, aiohttp, transformers, boto3, datasets, fashion-clip\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [fashion-clip][0m [datasets]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aiosignal-1.3.2 annoy-1.17.3 appdirs-1.4.4 boto3-1.38.35 botocore-1.38.35 datasets-3.6.0 dill-0.3.8 fashion-clip-0.2.2 frozenlist-1.7.0 hf-xet-1.1.3 huggingface-hub-0.33.0 ipyplot-1.1.2 jmespath-1.0.1 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-20.0.0 python-dotenv-1.1.0 regex-2024.11.6 s3transfer-0.13.0 safetensors-0.5.3 shortuuid-1.0.13 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4 validators-0.35.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision fashion-clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b46d16-dd03-4c9d-82fa-638e6978fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script fine-tunes a projection head on top of a frozen FashionCLIP image encoder using a triplet loss. \n",
    "It is designed to learn better visual embeddings for fashion images by bringing similar images closer and pushing dissimilar ones apart.\n",
    "\n",
    "Key components:\n",
    "\n",
    "Dataset Loader: Loads anchor, positive, and negative images from a CSV file and applies transforms.\n",
    "\n",
    "Projection Head: A simple linear layer that maps CLIP’s image features into a lower-dimensional normalized space.\n",
    "\n",
    "Loss Function: InfoNCE-based triplet loss that encourages anchor-positive pairs to be closer than anchor-negative pairs.\n",
    "\n",
    "Training Loop: For each epoch, it extracts image features using the frozen CLIP encoder, projects them, calculates the loss, \n",
    "and updates only the projection head.\n",
    "\n",
    "Evaluation (optional): Calculates average validation loss on a held-out triplet set.\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from fashion_clip.fashion_clip import FashionCLIP\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ff914-c94f-4376-95c2-b6c3cba33e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset \n",
    "!pip install gdown\n",
    "gdown --folder 1g-2bfL18NnH9lWxuiedlGOLlFPXr98Ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e4676b4-7749-4b7a-ad0e-7443576d2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 80\n",
      "Val samples: 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TripletFashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def find_image_path(name):\n",
    "            for ext in ['.jpg', '.png']:\n",
    "                path = os.path.join(self.image_folder, name + ext)\n",
    "                if os.path.exists(path):\n",
    "                    return path\n",
    "            raise FileNotFoundError(f\"Image {name} not found in supported formats.\")\n",
    "\n",
    "        a = find_image_path(self.data.iloc[idx, 0])\n",
    "        p = find_image_path(self.data.iloc[idx, 1])\n",
    "        n = find_image_path(self.data.iloc[idx, 2])\n",
    "\n",
    "        return self.transform(Image.open(a).convert(\"RGB\")), \\\n",
    "               self.transform(Image.open(p).convert(\"RGB\")), \\\n",
    "               self.transform(Image.open(n).convert(\"RGB\"))\n",
    "        \n",
    "train_dataset = TripletFashionDataset(\"train_triplets.csv\",\"./fashion_images\")\n",
    "val_dataset = TripletFashionDataset(\"val_triplets.csv\",\"./fashion_images\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e1083c6-ea3e-4479-87a2-545be5b5b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=512, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.fc(x), p=2, dim=-1)\n",
    "\n",
    "def info_nce_loss(anchor, positive, negative, temperature=0.07):\n",
    "    sim_ap = (anchor * positive).sum(dim=-1) / temperature\n",
    "    sim_an = (anchor * negative).sum(dim=-1) / temperature\n",
    "    logits = torch.cat([sim_ap.unsqueeze(1), sim_an.unsqueeze(1)], dim=1)\n",
    "    labels = torch.zeros(anchor.size(0), dtype=torch.long, device=anchor.device)\n",
    "    return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f3f4ac6-5e02-4f8a-88e1-52a300ec0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, epochs=5, batch_size=16, lr=1e-4, output_path='projection_head.pth'):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load and freeze FashionCLIP\n",
    "    fclip = FashionCLIP('fashion-clip')\n",
    "    clip_model = fclip.model\n",
    "    clip_model.eval()\n",
    "    for param in clip_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Projection head and optimizer\n",
    "    projector = ProjectionHead(input_dim=512, output_dim=256).to(device)\n",
    "    optimizer = torch.optim.Adam(projector.parameters(), lr=lr)\n",
    "\n",
    "    def extract_features(anchor_img, positive_img, negative_img):\n",
    "        \"\"\"extract image features with CLIP.\"\"\"\n",
    "        anchor_img = anchor_img.to(device)\n",
    "        positive_img = positive_img.to(device)\n",
    "        negative_img = negative_img.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            a_feat = clip_model.get_image_features(pixel_values=anchor_img)\n",
    "            p_feat = clip_model.get_image_features(pixel_values=positive_img)\n",
    "            n_feat = clip_model.get_image_features(pixel_values=negative_img)\n",
    "        return a_feat, p_feat, n_feat\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # === Training ===\n",
    "        projector.train()\n",
    "        total_train_loss = 0\n",
    "        for anchor_img, positive_img, negative_img in train_loader:\n",
    "            a_feat, p_feat, n_feat = extract_features(anchor_img, positive_img, negative_img)\n",
    "\n",
    "            a_proj = projector(a_feat)\n",
    "            p_proj = projector(p_feat)\n",
    "            n_proj = projector(n_feat)\n",
    "\n",
    "            loss = info_nce_loss(a_proj, p_proj, n_proj)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        projector.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for anchor_img, positive_img, negative_img in val_loader:\n",
    "                a_feat, p_feat, n_feat = extract_features(anchor_img, positive_img, negative_img)\n",
    "\n",
    "                a_proj = projector(a_feat)\n",
    "                p_proj = projector(p_feat)\n",
    "                n_proj = projector(n_feat)\n",
    "\n",
    "                val_loss = info_nce_loss(a_proj, p_proj, n_proj)\n",
    "                total_val_loss += val_loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    torch.save(projector.state_dict(), output_path)\n",
    "    print(f\"✅ Projection head saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fae6c262-1e5b-443f-9165-037e5b3926cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Train Loss: 0.1875 | Val Loss: 0.0401\n",
      "Epoch [2/20] - Train Loss: 0.1111 | Val Loss: 0.0339\n",
      "Epoch [3/20] - Train Loss: 0.0661 | Val Loss: 0.0293\n",
      "Epoch [4/20] - Train Loss: 0.0419 | Val Loss: 0.0257\n",
      "Epoch [5/20] - Train Loss: 0.0275 | Val Loss: 0.0229\n",
      "Epoch [6/20] - Train Loss: 0.0180 | Val Loss: 0.0206\n",
      "Epoch [7/20] - Train Loss: 0.0125 | Val Loss: 0.0189\n",
      "Epoch [8/20] - Train Loss: 0.0097 | Val Loss: 0.0173\n",
      "Epoch [9/20] - Train Loss: 0.0073 | Val Loss: 0.0160\n",
      "Epoch [10/20] - Train Loss: 0.0058 | Val Loss: 0.0150\n",
      "Epoch [11/20] - Train Loss: 0.0047 | Val Loss: 0.0142\n",
      "Epoch [12/20] - Train Loss: 0.0041 | Val Loss: 0.0134\n",
      "Epoch [13/20] - Train Loss: 0.0035 | Val Loss: 0.0128\n",
      "Epoch [14/20] - Train Loss: 0.0031 | Val Loss: 0.0123\n",
      "Epoch [15/20] - Train Loss: 0.0027 | Val Loss: 0.0118\n",
      "Epoch [16/20] - Train Loss: 0.0025 | Val Loss: 0.0114\n",
      "Epoch [17/20] - Train Loss: 0.0022 | Val Loss: 0.0110\n",
      "Epoch [18/20] - Train Loss: 0.0020 | Val Loss: 0.0107\n",
      "Epoch [19/20] - Train Loss: 0.0019 | Val Loss: 0.0104\n",
      "Epoch [20/20] - Train Loss: 0.0017 | Val Loss: 0.0101\n",
      "✅ Projection head saved to: projection_head.pth\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    lr=1e-4,\n",
    "    output_path='projection_head.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6475b0-5a69-4b67-b5b3-c7d74f4bcebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
